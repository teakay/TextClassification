{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from bs4 import BeautifulSoup\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Load and parse data from xml file\n",
    "#todo : add other info such as title, isbn and date publish as data\n",
    "def load_data(path):\n",
    "    doc = open(path,encoding='utf8').read()\n",
    "    xmldata = BeautifulSoup(doc, \"html.parser\")\n",
    "\n",
    "    data = []\n",
    "    for book in xmldata.findAll('book'):\n",
    "        parse_xml = BeautifulSoup(str(book),\"html.parser\")\n",
    "        blurb = str(parse_xml.find('body').string)\n",
    "        topcategory = str(parse_xml.find(\"topic\",{\"d\":\"0\"}).string)\n",
    "        data.append((blurb, topcategory))\n",
    "\n",
    "    return data\n",
    "\n",
    "#load train data\n",
    "text_train = load_data('C:\\\\workspace\\\\germeval2019t1datasets\\\\blurbs_train.txt')\n",
    "blurbs_train = [text[0] for text in text_train]\n",
    "y = [text[1] for text in text_train]\n",
    "\n",
    "#Convert to tf-idf vector\n",
    "stopwords = get_stop_words('de') + list(punctuation)\n",
    "#vectorizer = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "X = vectorizer.fit_transform(blurbs_train) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= Decision Tree Evaluation ==============================\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "      Architektur & Garten       0.30      0.21      0.24        29\n",
      "Ganzheitliches Bewusstsein       0.38      0.22      0.27       139\n",
      "            Glaube & Ethik       0.35      0.30      0.32        98\n",
      "   Kinderbuch & Jugendbuch       0.44      0.42      0.43       377\n",
      "                    Künste       0.38      0.10      0.15        31\n",
      "  Literatur & Unterhaltung       0.73      0.80      0.76      1490\n",
      "                  Ratgeber       0.50      0.50      0.50       344\n",
      "                  Sachbuch       0.40      0.37      0.38       402\n",
      "\n",
      "                  accuracy                           0.60      2910\n",
      "                 macro avg       0.43      0.36      0.38      2910\n",
      "              weighted avg       0.58      0.60      0.59      2910\n",
      "\n",
      "0.597594501718213\n"
     ]
    }
   ],
   "source": [
    "#===============================   Decision Tree ====================================\n",
    "#DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)\n",
    "\n",
    "dtclassifier = DecisionTreeClassifier()\n",
    "dtmodel = dtclassifier.fit(X_train, y_train)\n",
    "\n",
    "#predict\n",
    "y_prediction = dtmodel.predict(X_test)\n",
    "\n",
    "#Model evaluation\n",
    "print(\"========================= Decision Tree Evaluation ==============================\")\n",
    "print(classification_report(y_test,y_prediction))\n",
    "print(\"Accuracy score : \".accuracy_score(y_test, y_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= Random Forest Evaluation ==============================\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "      Architektur & Garten       0.00      0.00      0.00        29\n",
      "Ganzheitliches Bewusstsein       0.79      0.14      0.23       139\n",
      "            Glaube & Ethik       0.89      0.16      0.28        98\n",
      "   Kinderbuch & Jugendbuch       0.90      0.25      0.39       377\n",
      "                    Künste       0.00      0.00      0.00        31\n",
      "  Literatur & Unterhaltung       0.65      0.99      0.78      1490\n",
      "                  Ratgeber       0.67      0.62      0.64       344\n",
      "                  Sachbuch       0.68      0.26      0.37       402\n",
      "\n",
      "                  accuracy                           0.66      2910\n",
      "                 macro avg       0.57      0.30      0.34      2910\n",
      "              weighted avg       0.69      0.66      0.60      2910\n",
      "\n",
      "0.6618556701030928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#================================ Random Forest  ======================================\n",
    "#RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "rfclassifier = RandomForestClassifier(n_estimators=100)\n",
    "rfclassifier = rfclassifier.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "y_prediction = rfclassifier.predict(X_test)\n",
    "#print(prediction)\n",
    "\n",
    "#Model evaluation\n",
    "print(\"========================= Random Forest Evaluation ==============================\")\n",
    "print(classification_report(y_test,y_prediction))\n",
    "print(\"Accuracy score : \".accuracy_score(y_test, y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= AdaBoost  Evaluation ==============================\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "      Architektur & Garten       0.70      0.24      0.36        29\n",
      "Ganzheitliches Bewusstsein       0.50      0.01      0.01       139\n",
      "            Glaube & Ethik       0.12      0.03      0.05        98\n",
      "   Kinderbuch & Jugendbuch       0.20      0.03      0.05       377\n",
      "                    Künste       0.33      0.16      0.22        31\n",
      "  Literatur & Unterhaltung       0.59      0.94      0.72      1490\n",
      "                  Ratgeber       0.40      0.14      0.21       344\n",
      "                  Sachbuch       0.33      0.26      0.29       402\n",
      "\n",
      "                  accuracy                           0.54      2910\n",
      "                 macro avg       0.40      0.23      0.24      2910\n",
      "              weighted avg       0.46      0.54      0.45      2910\n",
      "\n",
      "0.540893470790378\n"
     ]
    }
   ],
   "source": [
    "#================================ XGBoost  ======================================\n",
    "#AdaBoostClassifier(base_estimator=None, *, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)\n",
    "abclassifier = AdaBoostClassifier(n_estimators=100)\n",
    "abmodel = abclassifier.fit(X_train, y_train)\n",
    "\n",
    "#predict\n",
    "y_prediction = abmodel.predict(X_test)\n",
    "\n",
    "#Model evaluation\n",
    "print(\"========================= AdaBoost  Evaluation ==============================\")\n",
    "print(classification_report(y_test,y_prediction))\n",
    "print(\"Accuracy score : \".accuracy_score(y_test, y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
